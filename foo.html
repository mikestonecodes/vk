<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>WebGPU Graphics Shader Demo</title>
    <style>
      body {
        margin: 0;
        font-family: sans-serif;
        background: #111;
        color: #eee;
      }
      #canvas {
        display: block;
      }
      #info {
        position: absolute;
        top: 10px;
        left: 10px;
        background: rgba(0, 0, 0, 0.7);
        padding: 10px;
      }
    </style>
  </head>
  <body>
    <div id="info">
      <div>Status: <span id="status">Initializing...</span></div>
      <div>Particles: <span id="particles">0</span></div>
    </div>
    <canvas id="canvas" width="800" height="600"></canvas>

    <script type="module">
      let device, context, pipeline, computePipeline, postProcessPipeline;
      let particleBuffer,
        uniformBuffer,
        computeUniformBuffer,
        postProcessUniformBuffer;
      let bindGroup, computeBindGroup, postProcessBindGroup;
      let texture, sampler;
      let renderTexture, renderTextureView, depthTexture, depthTextureView;
      let vertexBuffer;

      const PARTICLE_COUNT = 5000;

      async function init() {
        const canvas = document.getElementById("canvas");
        const status = document.getElementById("status");
        const particleCount = document.getElementById("particles");

        if (!navigator.gpu) {
          status.textContent = "WebGPU not supported";
          return;
        }

        try {
          // Get WebGPU adapter and device
          const adapter = await navigator.gpu.requestAdapter();
          device = await adapter.requestDevice();

          // Configure canvas
          context = canvas.getContext("webgpu");
          const format = "bgra8unorm";
          context.configure({
            device,
            format,
            alphaMode: "premultiplied",
          });

          // Load all WGSL shaders
          const [graphicsResponse, computeResponse, postProcessResponse] =
            await Promise.all([
              fetch("graphics.wgsl"),
              fetch("compute.wgsl"),
              fetch("post_process.wgsl"),
            ]);
          const [graphicsCode, computeCode, postProcessCode] =
            await Promise.all([
              graphicsResponse.text(),
              computeResponse.text(),
              postProcessResponse.text(),
            ]);

          // Adapt shaders for WebGPU (no push constants)
          const adaptedGraphicsShader = graphicsCode.replace(
            /var<push_constant> push_constants: PushConstants;/g,
            "@group(0) @binding(3) var<uniform> push_constants: PushConstants;",
          );

          const adaptedComputeShader = computeCode.replace(
            /var<push_constant> push_constants: PushConstants;/g,
            "@group(0) @binding(1) var<uniform> push_constants: PushConstants;",
          );

          const adaptedPostProcessShader = postProcessCode.replace(
            /var<push_constant> push_constants: PushConstants;/g,
            "@group(0) @binding(2) var<uniform> push_constants: PushConstants;",
          );

          // Create shader modules
          const graphicsShaderModule = device.createShaderModule({
            code: adaptedGraphicsShader,
          });

          const computeShaderModule = device.createShaderModule({
            code: adaptedComputeShader,
          });

          const postProcessShaderModule = device.createShaderModule({
            code: adaptedPostProcessShader,
          });

          // Create render target texture for first pass
          renderTexture = device.createTexture({
            label: "Offscreen Render Target",
            size: [canvas.width, canvas.height],
            format,
            usage:
              GPUTextureUsage.RENDER_ATTACHMENT |
              GPUTextureUsage.TEXTURE_BINDING,
          });
          renderTextureView = renderTexture.createView({
            label: "Offscreen Render Target View",
          });

          // Create depth texture for proper depth testing
          depthTexture = device.createTexture({
            label: "Depth Buffer",
            size: [canvas.width, canvas.height],
            format: "depth24plus",
            usage: GPUTextureUsage.RENDER_ATTACHMENT,
          });
          depthTextureView = depthTexture.createView({
            label: "Depth Buffer View",
          });

          // No vertex buffer needed - graphics shader uses built-in quad vertices

          // Create render pipeline with optimization flags and depth testing
          pipeline = device.createRenderPipeline({
            label: "Particle Render Pipeline",
            layout: "auto",
            vertex: {
              module: graphicsShaderModule,
              entryPoint: "vs_main",
            },
            fragment: {
              module: graphicsShaderModule,
              entryPoint: "fs_main",
              targets: [
                {
                  format,
                  blend: {
                    color: {
                      srcFactor: "src-alpha",
                      dstFactor: "one-minus-src-alpha",
                    },
                    alpha: {
                      srcFactor: "one",
                      dstFactor: "one-minus-src-alpha",
                    },
                  },
                },
              ],
            },
            primitive: {
              topology: "triangle-list",
              cullMode: "back",
              frontFace: "ccw",
            },
            depthStencil: {
              depthWriteEnabled: true,
              depthCompare: "less",
              format: "depth24plus",
            },
          });

          // Create compute pipeline with optimization flags
          computePipeline = device.createComputePipeline({
            label: "Particle Compute Pipeline",
            layout: "auto",
            compute: {
              module: computeShaderModule,
              entryPoint: "main",
            },
          });

          // Create post-process pipeline with optimization flags
          postProcessPipeline = device.createRenderPipeline({
            label: "Post Process Pipeline",
            layout: "auto",
            vertex: {
              module: postProcessShaderModule,
              entryPoint: "vs_main",
            },
            fragment: {
              module: postProcessShaderModule,
              entryPoint: "fs_main",
              targets: [
                {
                  format,
                },
              ],
            },
            primitive: {
              topology: "triangle-list",
              cullMode: "back",
            },
          });

          // Create particle data
          const particleData = new Float32Array(PARTICLE_COUNT * 6); // vec2 position + vec3 color + 1 padding
          // Create particle buffer (for compute and graphics)
          particleBuffer = device.createBuffer({
            label: "Particle Data Buffer",
            size: particleData.byteLength,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
          });
          device.queue.writeBuffer(particleBuffer, 0, particleData);

          // Create combined uniform buffer with 256-byte alignment
          const combinedUniformSize = 256 * 3; // 256 bytes each for graphics, compute, and post-process
          uniformBuffer = device.createBuffer({
            label: "Combined Uniform Buffer",
            size: combinedUniformSize,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
          });
          // Use same buffer for all three pipelines
          computeUniformBuffer = uniformBuffer;
          postProcessUniformBuffer = uniformBuffer;

          // Load PNG texture
          const img = new Image();
          await new Promise((resolve, reject) => {
            img.onload = resolve;
            img.onerror = reject;
            img.src = "test.png";
          });

          // Create canvas to get image data
          const canvas2d = document.createElement("canvas");
          const ctx = canvas2d.getContext("2d");
          canvas2d.width = img.width;
          canvas2d.height = img.height;
          ctx.drawImage(img, 0, 0);
          const imageData = ctx.getImageData(0, 0, img.width, img.height);

          texture = device.createTexture({
            size: [img.width, img.height, 1],
            format: "rgba8unorm",
            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST,
          });
          device.queue.writeTexture(
            { texture },
            imageData.data,
            { bytesPerRow: img.width * 4 },
            [img.width, img.height, 1],
          );

          // Create sampler
          sampler = device.createSampler({
            magFilter: "linear",
            minFilter: "linear",
          });

          // Create bind groups
          bindGroup = device.createBindGroup({
            layout: pipeline.getBindGroupLayout(0),
            entries: [
              { binding: 0, resource: { buffer: particleBuffer } },
              { binding: 1, resource: sampler },
              { binding: 2, resource: texture.createView() },
              {
                binding: 3,
                resource: { buffer: uniformBuffer, offset: 0, size: 8 },
              },
            ],
          });

          computeBindGroup = device.createBindGroup({
            layout: computePipeline.getBindGroupLayout(0),
            entries: [
              { binding: 0, resource: { buffer: particleBuffer } },
              {
                binding: 1,
                resource: { buffer: uniformBuffer, offset: 256, size: 8 },
              },
            ],
          });

          postProcessBindGroup = device.createBindGroup({
            layout: postProcessPipeline.getBindGroupLayout(0),
            entries: [
              { binding: 0, resource: renderTextureView },
              { binding: 1, resource: sampler },
              {
                binding: 2,
                resource: { buffer: uniformBuffer, offset: 256, size: 8 },
              },
            ],
          });

          // Write constant uniform data once during initialization
          uniformData[0] = canvas.width;
          uniformData[1] = canvas.height;
          device.queue.writeBuffer(uniformBuffer, 0, uniformData);

          // Write initial time and particle count
          device.queue.writeBuffer(uniformBuffer, 256, startTimeBuffer);

          status.textContent = "Ready";
          particleCount.textContent = PARTICLE_COUNT;

          // Start render loop
          render();
        } catch (error) {
          console.error(error);
          status.textContent = "Error: " + error.message;
        }
      }

      let startTime = performance.now();

      // Pre-allocate uniform buffers with 256-byte alignment
      const uniformData = new Int32Array(2); // Graphics uniforms

      // Pre-calculate compute dispatch size
      const computeWorkgroups = PARTICLE_COUNT/ 64;

      // Write start time once - shaders will calculate elapsed time
      const startTimeBuffer = new Float32Array([
        startTime / 1000.0,
        PARTICLE_COUNT,
      ]);
      const postProcessStartBuffer = new Float32Array([
        startTime / 1000.0,
        1.5,
      ]);

      function render() {
        const currentTime = (performance.now() - startTime) / 1000.0;

        // Single time write - post-process will read same time from compute buffer
        const timeBuffer = new Float32Array([currentTime, PARTICLE_COUNT]);
        device.queue.writeBuffer(uniformBuffer, 256, timeBuffer);

        // Create command encoder (required per frame in WebGPU)
        const commandEncoder = device.createCommandEncoder({
          label: "Frame Commands",
        });

        // 1. Compute pass - animate particles (use pre-calculated workgroups)
        const computePass = commandEncoder.beginComputePass({
          label: "Particle Animation",
        });
        computePass.setPipeline(computePipeline);
        computePass.setBindGroup(0, computeBindGroup);
        computePass.dispatchWorkgroups(computeWorkgroups);
        computePass.end();

        // 2. Render pass - draw particles to off-screen texture with depth testing
        const renderPass = commandEncoder.beginRenderPass({
          label: "Particle Render",
          colorAttachments: [
            {
              view: renderTextureView,
              clearValue: { r: 0.0, g: 0.0, b: 0.1, a: 1.0 },
              loadOp: "clear",
              storeOp: "store",
            },
          ],
          depthStencilAttachment: {
            view: depthTextureView,
            depthClearValue: 1.0,
            depthLoadOp: "clear",
            depthStoreOp: "store",
          },
        });

        renderPass.setPipeline(pipeline);
        renderPass.setBindGroup(0, bindGroup);
        renderPass.draw(6, PARTICLE_COUNT);
        renderPass.end();

        // 3. Post-process pass - apply bloom and effects to final screen
        const currentTexture = context.getCurrentTexture();
        const postProcessPass = commandEncoder.beginRenderPass({
          label: "Post Process",
          colorAttachments: [
            {
              view: currentTexture.createView(),
              clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
              loadOp: "clear",
              storeOp: "store",
            },
          ],
        });

        postProcessPass.setPipeline(postProcessPipeline);
        postProcessPass.setBindGroup(0, postProcessBindGroup);
        postProcessPass.draw(3);
        postProcessPass.end();

        // Submit commands and immediately request next frame
        const commandBuffer = commandEncoder.finish();
        device.queue.submit([commandBuffer]);
        requestAnimationFrame(render);
      }

      // Start the application
      init();
    </script>
  </body>
</html>

